<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/logo.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="zhangXiaolong">
  <meta name="keywords" content="">
  <title>2017-08-07@Bi-weekly - AI-performance</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/qtcreator-dark.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 5.0.2"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>AI Performance</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                导航入口
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/2.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2017-08-07 08:00">
      2017年8月7日 早上
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      1.8k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      28
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h1 id="嵌入式AI-双周简报-2017-08-07"><a href="#嵌入式AI-双周简报-2017-08-07" class="headerlink" title="嵌入式AI 双周简报 (2017-08-07)"></a>嵌入式AI 双周简报 (2017-08-07)</h1><h2 id="业界新闻"><a href="#业界新闻" class="headerlink" title="业界新闻"></a>业界新闻</h2><ul>
<li><a target="_blank" rel="noopener" href="http://opencv.org/opencv-3-3.html">OpenCV 3.3版本发布</a>  </li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28323601?utm_source=wechat_timeline&utm_medium=social&from=timeline">鱼和熊掌兼得，DNN加入 OpenCV 全家桶 | 知乎专栏</a>  </li>
<li><a target="_blank" rel="noopener" href="https://developer.qualcomm.com/software/snapdragon-neural-processing-engine">Qualcomm Snapdragon Neural Processing Engine (NPE) | Qualcomm Developer Network</a>  </li>
<li><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s/WlZTXCRy0xGeuJLQMxZGeQ">AI让芯片业洗牌: 苹果、微软和谷歌挤入赛道，英特尔、英伟达、高通、AMD几家欢乐几家愁 | 新智元</a>  </li>
<li><a target="_blank" rel="noopener" href="http://www.sohu.com/a/162189343_610300">解密图森：英伟达为何投资这家无人车公司；估值18亿背后有位长者 | 量子位</a>  </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?src=3&timestamp=1502018174&ver=1&signature=UozfhYMHOaRae6vesHbE0yvQl8DqpLOL5ru3ZXmsKHVAUaiot1ZdwO6KVmCEe7TVhPO1DlSEsgl-*X8wwn95LDDoauBV*GJIlk*DWEgLhmdZ5gddTV90tMZybHzU4iyJy7n3SZfs99YI4GewOq3LFpwPkrcGBIE20iavJ6jnDaM=">被英伟达相中，给Tier1供货，天瞳威视仅靠AI就搞定ADAS | 车东西</a>  </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?src=3&timestamp=1502018201&ver=1&signature=gUEmNUHy8y-SoCfrsriCmcDhzptEE4mc0M9tSLutgZ7ao2TvO25ZLK0iqVLspVKOADxdgPe3tu0IrjdlVtfx4aek4KEufToHuOAz2eXGro2OoeY8Yry0KfC47D8H8B0XiJvv-2G-PKJQN378zkUovM9LwC5SkxceA-8pa6t*-D4=">ARM的最新NB-IoT报告 | 5G</a>  </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzI2NTM2OTc1Nw==&mid=2247485358&idx=1&sn=1fb5f161cbf80093d952186dc5e8f02c&scene=45#wechat_redirect">ARM发飙！几个月后手机处理器将因它们而变天！ | 智趣狗</a>  </li>
<li><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s/G_OEZJ0a62TZuMRq5jpXmA">人工智能和云计算让芯片业洗牌，英特尔成了最大输家 | 量子位</a>  </li>
<li><a target="_blank" rel="noopener" href="https://www.wired.com/story/the-rise-of-ai-is-forcing-google-and-microsoft-to-become-chipmakers/">The Rise of AI Is Forcing Google and Microsoft to Become Chipmakers | WIRED</a>  </li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/62871439">如何评价腾讯刚出的ncnn库？ | 知乎</a>  </li>
<li><a target="_blank" rel="noopener" href="http://www.sohu.com/a/160700395_473283">沈向洋宣布微软开发 AI 芯片HPU，剑指英伟达等芯片巨头软肋 | 新智元</a>  </li>
<li><a target="_blank" rel="noopener" href="http://www.sohu.com/a/160215465_473283">超越GPU，FPGA、ASIC和更智能的手机 ｜ 新智元</a>  </li>
<li><a target="_blank" rel="noopener" href="https://tenso.rs/">“TensorFire - runs neural networks in the browser using WebGL”</a> <a target="_blank" rel="noopener" href="https://tenso.rs/demos/fast-neural-style/">[Demo: style-transfer]</a>  </li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=f39NFuZAj6s">Getting Started with Neural Compute Stick and Rasbperry Pi 3 | YouTube</a></li>
</ul>
<h2 id="论文-幻灯片"><a href="#论文-幻灯片" class="headerlink" title="论文/幻灯片"></a>论文/幻灯片</h2><ul>
<li>[CVPR2017] <a target="_blank" rel="noopener" href="http://image-net.org/challenges/talks_2017/SENet.pdf">Squeeze-and-Excitation networks (ILSVRC 2017 winner) at CVPR2017</a>  </li>
<li>[1707.06990] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.06990">Memory-Efficient Implementation of DenseNets</a>  </li>
<li><a target="_blank" rel="noopener" href="http://www.eecs.harvard.edu/~htk/publication/2016-icpr-teerapittayanon-mcdanel-kung.pdf">BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks</a>  </li>
<li><a target="_blank" rel="noopener" href="http://www.cs.jhu.edu/~jason/papers/vieira+eisner.tacl17.pdf">Learning to Prune: Exploring the Frontier of Fast and Accurate Parsing</a> <a target="_blank" rel="noopener" href="https://github.com/timvieira/learning-to-prune">[code]</a>  </li>
<li>[1704.06904] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1704.06904.pdf">Residual Attention Network for Image Classification</a> <a target="_blank" rel="noopener" href="https://github.com/buptwangfei/residual-attention-network">[code]</a>  </li>
<li>[1707.09102] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.09102">Fine-Pruning: Joint Fine-Tuning and Compression of a Convolutional Network with Bayesian Optimization</a>  </li>
<li>[1708.00999] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.00999">Extreme Low Resolution Activity Recognition with Multi-Siamese Embedding Learning</a>  </li>
<li>[1608.01409] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1608.01409v5">Faster CNNs with Direct Sparse Convolutions and Guided Pruning</a>  </li>
<li>[1606.05316] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.05316v2">Learning Infinite-Layer Networks: Without the Kernel Trick</a>  </li>
<li>[1707.09422] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.09422v1">Hyperprofile-based Computation Offloading for Mobile Edge Networks</a>  </li>
<li>[1705.04630] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.04630v2">Forecasting using incomplete models</a>  </li>
<li>[1707.09068] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.09068v1">Tartan: Accelerating Fully-Connected and Convolutional Layers in Deep Learning Networks by Exploiting Numerical Precision Variability</a>  </li>
<li>[1707.09926] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.09926v1">A Framework for Super-Resolution of Scalable Video via Sparse Reconstruction of Residual Frames</a>  </li>
<li>[1707.09855] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.09855v1">Convolution with Logarithmic Filter Groups for Efficient Shallow CNN</a>  </li>
<li>[1707.09597] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.09597v1">ScanNet: A Fast and Dense Scanning Framework for Metastatic Breast Cancer Detection from Whole-Slide Images</a>  </li>
<li>[ASPLOS’17] <a target="_blank" rel="noopener" href="http://web.eecs.umich.edu/~jahausw/publications/kang2017neurosurgeon.pdf">Neurosurgeon: Collaborative intelligence between the cloud and mobile edge</a>  </li>
<li>[1604.08772] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1604.08772">Towards Conceptual Compression</a>  </li>
<li>[1608.02893] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1608.02893">Syntactically Informed Text Compression with Recurrent Neural Networks</a>  </li>
<li>[1608.05148] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1608.05148v2">Full Resolution Image Compression with Recurrent Neural Networks</a>  </li>
<li>[CVPR2017] <a target="_blank" rel="noopener" href="http://xujuefei.com/lbcnn.html">Local Binary Convolutional Neural Networks</a> <a target="_blank" rel="noopener" href="https://github.com/juefeix/lbcnn.torch">[code]</a>  </li>
<li>[1703.09746] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.09746v3">Coordinating Filters for Faster Deep Neural Networks</a>  </li>
<li>[1707.08005] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.08005v1">Towards Evolutional Compression</a>  </li>
<li>[ICML2017] <a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v70/sakr17a.html">Analytical Guarantees on Numerical Precision of Deep Neural Networks</a></li>
</ul>
<h2 id="开源项目"><a href="#开源项目" class="headerlink" title="开源项目"></a>开源项目</h2><p><strong>网络压缩</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/yonghenglh6/DepthwiseConvolution">yonghenglh6/DepthwiseConvolution: A personal mobile convolution implementation on caffe by liuhao.(only GPU)</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/liuzhuang13/DenseNet">liuzhuang13/DenseNet: Densely Connected Convolutional Networks, In CVPR 2017 (Best Paper Award)</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/kevinzakka/DenseNet">kevinzakka/DenseNet: PyTorch Implementation of “Densely Connected Convolutional Networks”</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/hollance/MobileNet-CoreML">hollance/MobileNet-CoreML: The MobileNet neural network using Apple’s new CoreML framework</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/AngusG/tensorflow-xnor-bnn">AngusG/tensorflow-xnor-bnn: BinaryNets in TensorFlow with XNOR GEMM op</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/jonathanmarek1/binarynet-tensorflow">jonathanmarek1/binarynet-tensorflow</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/farmingyard/caffe-mobilenet">farmingyard/caffe-mobilenet: A caffe implementation of mobilenet’s depthwise convolution layer</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/kedartatwawadi/NN_compression">kedartatwawadi/NN_compression</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/chuanqi305/MobileNet-SSD">chuanqi305/MobileNet-SSD: Caffe implementation of Google MobileNet SSD detection network, with pretrained weights on VOC0712 and mAP=0.727.</a>  </li>
</ul>
<p><strong>性能</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/hollance/BNNS-vs-MPSCNN">hollance/BNNS-vs-MPSCNN: Compares the speed of Apple’s two deep learning frameworks: BNNS and Metal Performance Shaders</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/DeepMark/deepmark">DeepMark/deepmark: THE Deep Learning Benchmarks</a>  </li>
</ul>
<p><strong>模型加密</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/OpenMined/syft">OpenMined/Syft: Homomorphically Encrypted Deep Learning Library</a>  </li>
</ul>
<p><strong>增强现实</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ProjectDent/ARKit-CoreLocation">ProjectDent/ARKit-CoreLocation: Combines the high accuracy of AR with the scale of GPS data</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/bjarnel/arkit-tictactoe">bjarnel/arkit-tictactoe: Tic-Tac-Toe implemented using ARKit+Scenekit</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/arirawr/ARKit-FloorIsLava">arirawr/ARKit-FloorIsLava: Basic ARKit example that detects planes and makes them lava.</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/exyte/ARTetris">exyte/ARTetris: Augmented Reality Tetris made with ARKit and SceneKit</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/bjarnel/arkit-portal">bjarnel/arkit-portal: Simple portal demo implemented with ARKit+SceneKit, the trick is to change the rendering order and render invisible “masks” to hide what’s inside.</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/bjarnel/scenekit-tictactoe">bjarnel/scenekit-tictactoe</a>  </li>
</ul>
<p><strong>安卓</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/madeye/yolo-android">madeye/yolo-android: Quantized Tiny Yolo Demo on Android</a>  </li>
</ul>
<p><strong>iOS</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/kingreza/SeeFood">kingreza/SeeFood: Inspired by HBO’s Silicon Valley: SeeFood is an iOS app that uses CoreML to detect various dishes</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/hollance/TensorFlow-iOS-Example">hollance/TensorFlow-iOS-Example: Source code for my blog post “Getting started with TensorFlow on iOS”</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/Naituw/CoreMLDemo">Naituw/CoreMLDemo: Demo for CoreML &amp; Vision Framework</a>  </li>
</ul>
<p><strong>模型应用</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/msracver/FCIS">msracver/FCIS: Fully Convolutional Instance-aware Semantic Segmentation</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/bearpaw/PyraNet">bearpaw/PyraNet: Code for “Learning Feature Pyramids for Human Pose Estimation” (ICCV 2017)</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/aquaviter/iot-demo-mxnet-greengrass">aquaviter/iot-demo-mxnet-greengrass</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/bearpaw/PyraNet">bearpaw/PyraNet: Code for “Learning Feature Pyramids for Human Pose Estimation” (ICCV 2017)</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/CongWeilin/mtcnn-caffe">CongWeilin/mtcnn-caffe: Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/foreverYoungGitHub/MTCNN">foreverYoungGitHub/MTCNN: Repository for “Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks”, implemented with Caffe, C++ interface.</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/oaid/mtcnn">OAID/mtcnn: C++ project to implement MTCNN, a perfect face detect algorithm, on different DL frameworks. The most popular frameworks: caffe/mxnet/tensorflow, are all suppported now</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/Seanlinx/mtcnn">Seanlinx/mtcnn: this repository is the implementation of MTCNN in MXnet</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/LaoDar/cnn_head_pose_estimator">LaoDar/cnn_head_pose_estimator: a simple and fast mxnet version CNN based head pose estimator</a>  </li>
</ul>
<p><strong>加速库/框架</strong>　</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/thomaspark-pkj/darknet-nnpack">Darknet with NNPACK: NNPACK was used to optimize Darknet without using a GPU. It is useful for embedded devices using ARM CPUs</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/naibaf7/libdnn">naibaf7/libdnn: Greentea LibDNN - a universal convolution implementation supporting CUDA and OpenCL</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/blei-lab/edward">blei-lab/edward: A library for probabilistic modeling, inference, and criticism. Deep generative models, variational inference. Runs on TensorFlow</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/dmlc/nnvm-fusion">dmlc/nnvm-fusion: Kernel Fusion and Runtime Compilation Based on NNVM</a>  </li>
</ul>
<p><strong>音频图像视频处理</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/MTG/essentia">MTG/essentia: C++ library for audio and music analysis, description and synthesis, including Python bindings</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/pili-engineering">Pili-完美直播体验（Pili Streaming Cloud）</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/pili-engineering/PLDroidMediaStreaming">pili-engineering/PLDroidMediaStreaming: PLDroidMediaStreaming 是 Pili 直播 SDK 的 Android 推流端，支持 RTMP 推流，h.264 和 AAC 编码，硬编、软编支持。具有丰富的数据和状态回调，方便用户根据自己的业务定制化开发。具有直播场景下的重要功能，如：美颜、背景音乐、水印等功能。PLDroidMediaStreaming 是现在目前重点维护的版本，自带采集模块也支持用户自己做采集端。</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/pili-engineering/PLDroidShortVideo">pili-engineering/PLDroidShortVideo: PLDroidShortVideo 是七牛推出的一款适用于 Android 平台的短视频 SDK，提供了包括美颜、滤镜、水印、断点录制、分段回删、视频编辑、混音特效、本地/云端存储在内的多种功能，支持高度定制以及二次开发。</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/pili-engineering/PLDroidPlayer">pili-engineering/PLDroidPlayer: PLDroidPlayer 是 Pili 直播 SDK 的安卓播放器。支持所有直播常用的格式，如：RTMP、HLS、FLV。拥有优秀的功能和特性，如：首屏秒开、追帧优化、丰富的数据和状态回调、硬解软解支持。而且可以根据自己的业务进行高度定制化开发。</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/pili-engineering/PLMediaStreamingKit">pili-engineering/PLMediaStreamingKit: PLMediaStreamingKit 是 Pili 直播 SDK 的 iOS 推流端，支持 RTMP 推流，h.264 和 AAC 编码，硬编、软编支持。具有丰富的数据和状态回调，方便用户根据自己的业务定制化开发。具有直播场景下的重要功能，如：美颜、背景音乐、水印等功能。</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/pili-engineering/PLShortVideoKit">pili-engineering/PLShortVideoKit: PLShortVideoKit 是七牛推出的一款适用于 iOS 平台的短视频 SDK，提供了包括美颜、滤镜、水印、断点录制、分段回删、视频编辑、混音特效、本地/云端存储在内的多种功能，支持高度定制以及二次开发。</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/pili-engineering/PLPlayerKit">pili-engineering/PLPlayerKit: PLPlayerKit 是 Pili 直播 SDK 的 iOS 播放器。支持所有直播常用的格式，如：RTMP、HLS、FLV。拥有优秀的功能和特性，如：首屏秒开、追帧优化、丰富的数据和状态回调、硬解软解支持。而且可以根据自己的业务进行高度定制化开发。</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/pili-engineering/PLPlayerKit">pili-engineering/PLPlayerKit: PLPlayerKit 是 Pili 直播 SDK 的 iOS 播放器。支持所有直播常用的格式，如：RTMP、HLS、FLV。拥有优秀的功能和特性，如：首屏秒开、追帧优化、丰富的数据和状态回调、硬解软解支持。而且可以根据自己的业务进行高度定制化开发。</a>  </li>
</ul>
<p><strong>其它</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/facebook/fb-caffe-exts">facebook/fb-caffe-exts: Some handy utility libraries and tools for the Caffe deep learning framework.</a>  </li>
<li><a target="_blank" rel="noopener" href="http://www.iotjs.net/">Samsung/iotjs: Platform for Internet of Things with JavaScript</a> <a target="_blank" rel="noopener" href="https://github.com/Samsung/iotjs">code</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/hollance/Forge">hollance/Forge: A neural network toolkit for Metal</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/christopher5106/FastAnnotationTool">christopher5106/FastAnnotationTool: A tool using OpenCV to annotate images for image classification, optical character reading, etc.</a>  </li>
<li><a target="_blank" rel="noopener" href="https://github.com/raphui/rnk">raphui/rnk: rnk is a RTOS targeting ARM architecture.</a></li>
</ul>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul>
<li><a target="_blank" rel="noopener" href="http://www.cs.technion.ac.il/~twerd/HandNet/">HandNet - A dataset of depth images of hands</a>  </li>
</ul>
<h2 id="博文-教程"><a href="#博文-教程" class="headerlink" title="博文/教程"></a>博文/教程</h2><ul>
<li><a target="_blank" rel="noopener" href="http://eyeriss.mit.edu/tutorial.html">Tutorial on Hardware Architectures for Deep Neural Networks | MIT MICRO-50</a>  </li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/25025596?refer=shanren7">基于mtcnn和facenet的实时人脸检测与识别系统开发 | 知乎专栏</a>  </li>
<li><a target="_blank" rel="noopener" href="https://hackernoon.com/creating-insanely-fast-image-classifiers-with-mobilenet-in-tensorflow-f030ce0a2991">Creating insanely fast image classifiers with MobileNet in TensorFlow | HACKERNOON</a>  </li>
<li><a target="_blank" rel="noopener" href="http://www.kdnuggets.com/2017/07/squeeze-most-from-training-data.html">How to squeeze the most from your training data | KDNUGGETS</a>  </li>
<li><a target="_blank" rel="noopener" href="http://blog.csdn.net/Best_Coder/article/details/76201275">Ubuntu16.04腾讯NCNN框架入门到应用 | CSDN</a>  </li>
<li><a target="_blank" rel="noopener" href="https://devblogs.nvidia.com/parallelforall/building-cuda-applications-cmake/?_lrsc=dca4b9d4-7747-48e0-b9a0-961aba39a657&ncid=so-twi-lt-799">Building Cross-Platform CUDA Applications with CMake | NVIDIA</a>  </li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLD5D5H5YL9SIjxj3IC019AprtgJAjIU3q">Caffe2 Bay Area Meetup (5/31/2017) | YouTube</a></li>
</ul>
<hr>
<p>Editor: 张先轶、袁帅</p>
<hr>
<p><a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" srcset="/img/loading.gif" /></a><br />本作品采用<a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。</p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/bi-weekly/">bi-weekly</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2017/08/22/bi-weekly/2017-08-22/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">2017-08-22@Bi-weekly</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2017/07/24/bi-weekly/2017-07-24/">
                        <span class="hidden-mobile">2017-07-24@Bi-weekly</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                <script src="https://utteranc.es/client.js"
        repo="bigbigzxl/commit-utterances"
        issue-term="pathname"
        label="AI-Performance"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://github.com/AI-performance" target="_blank" rel="nofollow noopener"><span>AI</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://ai-performance.com" target="_blank" rel="nofollow noopener">
        <span>Performance</span></a>
    </div>
    
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "2017-08-07@Bi-weekly&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
      icon: "§"
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>







  
  
    <script>
      !function (e, t, a) {
        function r() {
          for (var e = 0; e < s.length; e++) s[e].alpha <= 0 ? (t.body.removeChild(s[e].el), s.splice(e, 1)) : (s[e].y--, s[e].scale += .004, s[e].alpha -= .013, s[e].el.style.cssText = "left:" + s[e].x + "px;top:" + s[e].y + "px;opacity:" + s[e].alpha + ";transform:scale(" + s[e].scale + "," + s[e].scale + ") rotate(45deg);background:" + s[e].color + ";z-index:99999");
          requestAnimationFrame(r)
        }

        function n() {
          var t = "function" == typeof e.onclick && e.onclick;
          e.onclick = function (e) {
            t && t(), o(e)
          }
        }

        function o(e) {
          var a = t.createElement("div");
          a.className = "heart", s.push({
            el: a,
            x: e.clientX - 5,
            y: e.clientY - 5,
            scale: 1,
            alpha: 1,
            color: c()
          }), t.body.appendChild(a)
        }

        function i(e) {
          var a = t.createElement("style");
          a.type = "text/css";
          try {
            a.appendChild(t.createTextNode(e))
          } catch (t) {
            a.styleSheet.cssText = e
          }
          t.getElementsByTagName("head")[0].appendChild(a)
        }

        function c() {
          return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
        }

        var s = [];
        e.requestAnimationFrame = e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function (e) {
          setTimeout(e, 1e3 / 60)
        }, i(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"), n(), r()
      }(window, document);
    </script>
  











  

  

  

  

  

  





</body>
</html>
