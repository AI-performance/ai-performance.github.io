<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/logo.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="zhangXiaolong">
  <meta name="keywords" content="">
  <title>AI-performance</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/qtcreator-dark.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 5.0.2"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>AI Performance</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/bi-weekly/">
                <i class="iconfont icon-category-fill"></i>
                Bi-weekly
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/demo/">
                <i class="iconfont icon-link-fill"></i>
                demo
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/2.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-08-15 01:23">
      2020年8月15日 凌晨
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      40
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h1 id="嵌入式AI简报-2020-05-15"><a href="#嵌入式AI简报-2020-05-15" class="headerlink" title="嵌入式AI简报 (2020-05-15)"></a>嵌入式AI简报 (2020-05-15)</h1><p><strong>关注模型压缩、低比特量化、移动端推理加速优化、部署</strong>  </p>
<blockquote>
<p>导读：本次15条。「新闻」高通发布中端Soc 768G，骁龙875性能规格曝光，联发科方面跟进，发布天玑1000+，中高端的天玑800系列。CUDA11特性曝光。「论文」部分，一篇关于深度学习编译器架构的综述论文，详细剖析常用的设计思想，对现有的深度学习编译器进行全面总结。「开源」MNN PR一年来的总结回顾及armv8.2等新特性、PaddleLite PR对瑞芯微AI芯片的支持、OpenCL3.0发布、NervanaSystem当年关于GPU上的优化项目分析、TF新的Runtime。「博文」解析MegEngine的显存优化技术分析，Tengine和PaddleLite算子选择策略浅析。</p>
</blockquote>
<p>手机SOC方面较多，单独一段总结：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/DQ2aRx276KFUXFYGvHaMig">三星Exynos992曝光6nm制程可能超越骁龙865</a>，Imagination新闻频频，Imagination已经将IMG A系列GPU在多个市场中授权给了客户，首批搭载该IP的SoC器件将在今年供货，<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/sgPyQjLModuvpa8jLh352Q">高通与Imagination同时宣布支持Google的Android GPU Inspector在各家的Adreno或PowerVR GPU上的负载分析</a>，<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/cGezbnF8O-whKjpkMbl-bw">小米迎来高通Adreno GPU驱动更新 | Qualcomm中国</a>，<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/DncvhgPYRAld-jcvK_WLoQ">荣耀发布Play 4T新机，搭载中芯国际14nm代工的麒麟710A，且已成功量产</a>。  </p>
<h2 id="业界新闻"><a href="#业界新闻" class="headerlink" title="业界新闻"></a>业界新闻</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.netded.com/news/2020/051150357.html">Redmi K30 5G首发高通全新SoC 768G | 迷你手机网</a><br>摘要：从命名上看，骁龙768G是骁龙765G的升级版，应该类似于骁龙855和骁龙855+的关系。<br>根据爆料，骁龙768G处理器采用了1+1+4（2.8GHz+2.4GHz+1.8GHz）组合，GPU为Adreno 620，骁龙768G的2颗大核A76都提升了主频，GPU主频提升到了750MHz，整体性能提升在10%~15%。据测试安兔兔跑分达到了36万分。<br>并且骁龙768G采用7nm EUV工艺制程，是一款集成式双模5G SoC，CPU部分拥有两颗A76架构性能大核，相较骁龙765G，其主频部分提升到了2.8GHz，同时，骁龙768G的GPU频率也提升到了750MHz。  </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/3tLjsPUHjsQSGbtEcK75tQ">高通骁龙875性能规格曝光！或集成X60 5G基带，台积电5nm工艺 | 智东西</a><br>摘要：高通即将推出的骁龙875，将采用台积电5nm工艺预计2021年发布。此外，该芯片组规格代号为SM8350，其上一代骁龙865代号为SM8250。目前不清楚骁龙875芯片的5G调制解调器是否采用集成式方案。<br>性能方面，骁龙875采用Armv8 Cortex架构的Kryo 685 CPU，Adreno 660 GPU、Adreno 665 VPU和Adreno 1095 DPU，以及一颗Spectra 580图像处理引擎，支持3G/4G/5G调制解调器mmWave（毫米波）和低于6GHz频段。  </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/M6rm5rYER9U7idAD3ix1qQ">联发科天玑1000+升级亮相，中高端800系列发布 | 三易生活</a><br>摘要：GPU性能方面，天玑1000+在天玑1000的基础上增强，将屏幕高帧率显示的上限从120Hz提升到144Hz，新的“ＭiraVision 画质引擎”可实现独立AI处理单元（联发科叫APU）和专用画质处理电路的联动计算，支持4K分辨率视频的AI实时处理。无论是从5G、AI、GPU设计这些“底子”上的技术水准，还是从游戏与视频优化这些“面子”上锦上添花的功能来说，联发科的天玑1000+这次都算是更上了一层楼。<br>此外，作为联发科中高端系列的代表，也是天玑800系列的升级款，但命名上并不是天玑800+，很有可能会改名为天玑820。听说天玑800系列一共有三种工程方案，主频分别是中杯2.0GHz、大杯2.2GHz左右和超大杯2.6GHz左右。  </li>
<li><a target="_blank" rel="noopener" href="https://devblogs.nvidia.com/cuda-11-features-revealed/">CUDA 11 Features Revealed | NVIDIA Developer</a><br>摘要：The A100 GPU has revolutionary hardware capabilities and we’re excited to announce CUDA 11 in conjunction with A100.  <ol>
<li>Support for the NVIDIA Ampere GPU architecture, including the new NVIDIA A100 GPU for accelerated scale-up and scale-out of AI and HPC data centers; multi-GPU systems with the NVSwitch fabric such as the DGX A100 and HGX A100.</li>
<li>Multi-Instance GPU (MIG) partitioning capability that is particularly beneficial to cloud service providers (CSPs) for improved GPU utilization.</li>
<li>New third-generation Tensor Cores to accelerate mixed-precision, matrix operations on different data types, including TF32 and Bfloat16.</li>
<li>Programming and APIs for task graphs, asynchronous data movement, fine-grained synchronization, and L2 cache residency control.</li>
<li>Performance optimizations in CUDA libraries for linear algebra, FFTs, and matrix multiplication.</li>
<li>Updates to the Nsight product family of tools for tracing, profiling, and debugging of CUDA applications.</li>
<li>Full support on all major CPU architectures, across x86_64, Arm64 server and POWER architectures.</li>
</ol>
</li>
</ul>
<h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/139552817">一篇关于深度学习编译器架构的综述论文 | 知乎</a><br>标题：The Deep Learning Compiler: A Comprehensive Survey<br>链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2002.03794">https://arxiv.org/abs/2002.03794</a><br>摘要：目前还都没有全面分析深度学习编译器这种独特设计架构。本文详细剖析常用的设计思想，对现有的深度学习编译器进行全面总结，重点是面向深度学习的多级中间表示（IR）以及前后端的优化。具体来说，作者从各个方面对现有编译器做全面比较，对多级IR的设计进行了详细分析，并介绍了常用的优化技术。最后，文章强调对今后编译器潜在研究方向的一些见解。基本上这是深度学习编译器设计体系结构（不是硬件方面）的第一个综述。  </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/OHUPfgwxQEb2CxhBX0Ik3g">Facebook发布提高设备AI工作能效的AutoScale | 将门创投</a><br>摘要：Facebook和亚利桑那州立大学建立了一个支持AI减轻设备负荷的模型——AutoScale。AutoScale通过观察当前AI执行效率，包括算法架构特征和运行时间。协同处理器等硬件之间选择，找到能最大限度提高能效的硬件。<br>AutoScale基于强化学习算法，计算累计奖励(R值)，来选择AI工具的最佳运行方式。例如：对于给定的处理器，系统使用基于AI能效利用率的模型计算奖励，假设处理器内核消耗的功率是可变的，内核在繁忙和空闲状态下花费的时间不同，能源使用情况也不同。此外，当推理扩展到连接的数据中心时，AutoScale可以借助基于信号强度的模型来计算奖励，预测传输延迟度和网络消耗的能量。</li>
</ul>
<h2 id="开源项目"><a href="#开源项目" class="headerlink" title="开源项目"></a>开源项目</h2><blockquote>
<p>注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为<code>github.com/&lt;repo_owner&gt;/&lt;repo_name&gt;</code>。</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/VBE54nbPn8zmvh6l1UZaag">alibaba/MNN: 开源一年，阿里轻量级AI推理引擎MNN 1.0.0正式发布 | AI科技大本营</a><br>摘要：MNN在阿里巴巴集团内部得到广泛推广，覆盖了如手机淘宝、天猫、优酷、钉钉、闲鱼等20多个App。在这次release中，包括且不限于以下特点：<ol>
<li>新增模型训练的支持，从此MNN不再是单纯的推理引擎，可Quantization Aware Training (QAT)；</li>
<li>利用ARMv8.2指令集，获得了两倍的性能提升；</li>
<li>进一步完善Python工具链，累计新增超过150个接口；</li>
<li>开源了应用层开箱即用的解决方案MNNKit，包含了人脸跟踪与检测、人像分割、手势识别等。  </li>
</ol>
</li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/WwJ-Qv27AYUbkflSZa3sKg">PaddlePaddle/Paddle-Lite:百度PaddleLite适配瑞芯微AI芯片，携手加速AI应用落地 | 飞桨PaddlePaddle</a><br>摘要：百度PaddleLite与瑞芯微Rockchip旗下AI芯片RK1808、RK1806正式完成适配，充分兼容飞桨轻量化推理引擎Paddle Lite。<br>瑞芯微AI芯片RK1808及RK1806，内置独立NPU神经计算单元，INT8 算力高达3.0TOPs；采用22nm FD-SOI工艺，相同性能下的功耗相比主流28nm工艺产品降低约30%，在算力、性能、功耗等指标上均有优异的表现。经实测，瑞芯微AI芯片在Paddle Lite中运行MobileNet V1耗时仅为6.5 ms，帧率高达153.8 FPS，二者充分兼容并高效稳定运行。  </li>
<li><a target="_blank" rel="noopener" href="https://www.khronos.org/opencl/">OpenCL 3.0 release发布：更灵活、异步DMA扩展支持 | khronos.org</a><br>摘要：OpenCL 3.0 integrates subgroup functionality into the core specification, ships with a new OpenCL C 3.0 language specification, uses a new unified specification format, and introduces extensions for asynchronous data copies to enable a new class of embedded processors. The provisional OpenCL 3.0 specifications enable the developer community to provide feedback before the specifications and conformance tests are finalized.<br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/391599659">更多，见如何评价 OpenCL 3.0 | 知乎</a>  </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/OYSzol-vufiKPuU9YxtbuA">NervanaSystems/maxas:矩阵相乘在GPU上的终极优化：深度解析Maxas汇编器工作原理 | 机器之心</a><br>摘要：Nervana汇编代码生成器项目Maxas，可生成性能超过nVidia官方版本的矩阵相乘的GPU机器码，其作者 Scott Gray 在代码外提供了详细的文档<a target="_blank" rel="noopener" href="https://github.com/NervanaSystems/maxas/wiki/SGEMM">NervanaSystems/maxas/wiki/SGEMM</a>，本文可以看作按作者对该文档的理解进行的重写。  </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/62Eaa5iF6mH4N6eW4liAzg">tensorflow/runtime:全新的 TensorFlow 运行时 | TensorFlow</a><br>摘要：TensorFlow RunTime (TFRT) 旨在提供一个统一、可扩展的基础架构层，在各种领域特定硬件上实现一流性能。高效利用多线程主机的 CPU，支持完全异步的编程模型，同时专注于底层效率。<br>现有 TensorFlow 的设计初衷是针对图执行和训练工作负载搭建，而新运行时则首要关注即时执行和推理，同时注重架构可扩展性和模块化。更具体地说，TFRT 已实现以下设计亮点：<ol>
<li>为提升性能，TFRT 配备无锁计算图执行器，支持并行操作执行，且同步开销较低。此外，其还配备一个轻量的即时算子分发栈，便于异步即时 API 调用和提高效率；  </li>
<li>为了更加轻松地扩展 TF 技术栈，我们已将设备运行时与主机运行时（即驱动主机 CPU 和 I/O 工作的核心 TFRT 组件）解耦；  </li>
<li>为确保行为一致，TFRT 在即时和图执行模式中均使用通用抽象，例如形状函数和内核。<br>TFRT 还与 MLIR 紧密集成。例如：  </li>
<li>TFRT 利用 MLIR 的编译器基础架构，为特定目标的运行时执行计算图生成优化表征；</li>
<li>TFRT 使用 MLIR 的可扩展类型系统支持运行时中的任意 C++ 类型，消除了仅支持特定张量的限制。<br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/391811802">如何评价TensorFlow开源的新运行时TFRT | 知乎</a>  </li>
</ol>
</li>
</ul>
<h2 id="博文"><a href="#博文" class="headerlink" title="博文"></a>博文</h2><ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/N-bjcUEF4cQbH5vT0RM9CA">深度解析MegEngine亚线性显存优化技术 | 旷视研究院</a><br>摘要：深度学习框架有几种降低显存占用的常用方法，其示例如下：<ol>
<li>通过合适的梯度定义，让算子的梯度计算不再依赖于前向计算作为输入，从而in-place地完成算子的前向计算，比如Sigmoid、Relu等；</li>
<li>在生命周期没有重叠的算子之间共享显存；</li>
<li>通过额外的计算减少显存占用，比如利用梯度检查点重新计算中间结果的亚线性显存优化方法[1]；</li>
<li>通过额外的数据传输减少显存占用，比如把暂时不用的数据从GPU交换到CPU，需要时再从CPU交换回来。<br>上述显存优化技术在MegEngine中皆有不同程度的实现，这里重点讨论基于梯度检查点的亚线性显存优化技术。<br>此外，亚线性优化方法采用简单的网格搜索（grid search）选择检查点，MegEngine在此基础上增加遗传算法，采用边界移动、块合并、块分裂等策略，实现更细粒度的优化，进一步降低了显存占用。  </li>
</ol>
</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/122943688">FLOPs与模型推理速度 | 知乎</a><br>摘要：两个layer的FLOPs和参数量完全相同。但是推理速度方面，depthwise卷积要远远慢于普通卷积。其原因就是访存数据量的不同：<br>由于卷积计算本身已经是flatten的，不需要考虑重复读取问题，那么总共读取的数据量就是feature的大小加上卷积核weight的大小，对于普通卷积来说，总读取数据量为：<code>100*56*56 + 3*3*100*100 = 4.0e+05</code>。类似的，depthwise卷积读取的数据总量为：<code>56*56*10000 + 3*3*10000 = 3.1e+07</code>。<br>可以看到，在同等FLOPs的情况下，depthwise卷积对应的feature size比普通卷积大的多，受制于GPU访存带宽，过高的数据读取与写入量就成为了限制推理速度的瓶颈。  </li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/139241788">Tengine多平台的算子调度与选择分析 | 知乎</a><br>摘要：Tengine目前已开源部分的算子对不同平台有各自的实现和优化，包括不限于arm32、arm64、x86等。对于其余的算子则是通过加载reference算子实现。那么当模型执行时，对于多平台下的同一算子，Tengine是如何选择的呢，本文将会进行介绍与分析。  </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/jEB1McrkU8iay1klc0DIfQ">Paddle Lite底层backend的kernel选择策略 | NeuralTalk</a><br>摘要：Paddle Lite是Paddle Mobile和Anakin的推理框架继任者。定位安卓/iOS移动端，以及X86端在内的多场景高性能预测，兼容支持ONNX、TensorFlow、Caffe等模型的部署。本文将描述Paddle Lite在模型转换过程（模型转换opt工具）中，静态kernel选择的策略以及一些思考。</li>
</ul>
<h2 id="往期回顾"><a href="#往期回顾" class="headerlink" title="往期回顾"></a><a target="_blank" rel="noopener" href="https://github.com/ysh329/awesome-embedded-ai">往期回顾</a></h2><table>
<thead>
<tr>
<th align="center">2</th>
<th align="center">0</th>
<th align="center">2</th>
<th align="center">0</th>
</tr>
</thead>
<tbody><tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"><a href="../embedded-ai-report/2020-05-15.md">2020-05-15</a></td>
<td align="center"><a href="../embedded-ai-report/2020-04-26.md">2020-04-26</a></td>
</tr>
<tr>
<td align="center"><a href="../embedded-ai-report/2020-04-04.md">2020-04-04</a></td>
<td align="center"><a href="../embedded-ai-report/2020-03-19.md">2020-03-19</a></td>
<td align="center"><a href="../embedded-ai-report/2020-03-02.md">2020-03-02</a></td>
<td align="center"><a href="../embedded-ai-report/2020-02-16.md">2020-02-16</a></td>
</tr>
<tr>
<td align="center"><a href="../embedded-ai-report/2020-01-27.md">2020-01-27</a></td>
<td align="center"><a href="../embedded-ai-report/2020-01-06.md">2020-01-06</a></td>
<td align="center"><a href="../embedded-ai-report/2019-12-17.md">2019-12-17</a></td>
<td align="center"><a href="../embedded-ai-report/2019-12-02.md">2019-12-02</a></td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">9</td>
</tr>
<tr>
<td align="center"><a href="../embedded-ai-report/2019-11-30.md">2019-11-30</a></td>
<td align="center"><a href="../embedded-ai-report/2019-11-18.md">2019-11-18</a></td>
<td align="center"><a href="../embedded-ai-report/2019-10-31.md">2019-10-31</a></td>
<td align="center"><a href="../embedded-ai-report/2019-10-17.md">2019-10-17</a></td>
</tr>
<tr>
<td align="center"><a href="../embedded-ai-report/2019-10-03.md">2019-10-03</a></td>
<td align="center"><a href="../embedded-ai-report/2019-09-16.md">2019-09-16</a></td>
<td align="center"><a href="../embedded-ai-report/2019-08-30.md">2019-08-30</a></td>
<td align="center"><a href="../embedded-ai-report/2019-08-15.md">2019-08-15</a></td>
</tr>
<tr>
<td align="center"><a href="../embedded-ai-report/2019-07-30.md">2019-07-30</a></td>
<td align="center"><a href="../embedded-ai-report/2019-07-15.md">2019-07-15</a></td>
<td align="center"><a href="../embedded-ai-report/2019-06-29.md">2019-06-29</a></td>
<td align="center"><a href="../embedded-ai-report/2019-06-17.md">2019-06-17</a></td>
</tr>
<tr>
<td align="center"><a href="../embedded-ai-report/2019-05-30.md">2019-05-30</a></td>
<td align="center"><a href="../embedded-ai-report/2019-05-15.md">2019-05-15</a></td>
<td align="center"><a href="../embedded-ai-report/2019-04-27.md">2019-04-27</a></td>
<td align="center"><a href="../embedded-ai-report/2019-04-13.md">2019-04-13</a></td>
</tr>
<tr>
<td align="center"><a href="../embedded-ai-report/2019-03-31.md">2019-03-31</a></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<hr>
<p><img src="../wechat_qrcode.jpg" srcset="/img/loading.gif" alt="wechat_qrcode"></p>
<blockquote>
<p>往期回顾：见公众号主菜单【历史消息】</p>
</blockquote>
<ul>
<li>WeChat: NeuralTalk  </li>
<li>Editor: <a target="_blank" rel="noopener" href="https://github.com/ysh329">https://github.com/ysh329</a>  </li>
<li>Project: <a target="_blank" rel="noopener" href="https://github.com/ysh329/awesome-embedded-ai">https://github.com/ysh329/awesome-embedded-ai</a>  </li>
</ul>
<hr>
<p><a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" srcset="/img/loading.gif" /></a><br />本作品采用<a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。</p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/08/15/bi-weekly/2020-06-03/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile"></span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/08/15/bi-weekly/2020-04-26/">
                        <span class="hidden-mobile"></span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                

              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
      icon: "§"
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>







  
  
    <script>
      !function (e, t, a) {
        function r() {
          for (var e = 0; e < s.length; e++) s[e].alpha <= 0 ? (t.body.removeChild(s[e].el), s.splice(e, 1)) : (s[e].y--, s[e].scale += .004, s[e].alpha -= .013, s[e].el.style.cssText = "left:" + s[e].x + "px;top:" + s[e].y + "px;opacity:" + s[e].alpha + ";transform:scale(" + s[e].scale + "," + s[e].scale + ") rotate(45deg);background:" + s[e].color + ";z-index:99999");
          requestAnimationFrame(r)
        }

        function n() {
          var t = "function" == typeof e.onclick && e.onclick;
          e.onclick = function (e) {
            t && t(), o(e)
          }
        }

        function o(e) {
          var a = t.createElement("div");
          a.className = "heart", s.push({
            el: a,
            x: e.clientX - 5,
            y: e.clientY - 5,
            scale: 1,
            alpha: 1,
            color: c()
          }), t.body.appendChild(a)
        }

        function i(e) {
          var a = t.createElement("style");
          a.type = "text/css";
          try {
            a.appendChild(t.createTextNode(e))
          } catch (t) {
            a.styleSheet.cssText = e
          }
          t.getElementsByTagName("head")[0].appendChild(a)
        }

        function c() {
          return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
        }

        var s = [];
        e.requestAnimationFrame = e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function (e) {
          setTimeout(e, 1e3 / 60)
        }, i(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"), n(), r()
      }(window, document);
    </script>
  











  

  

  

  

  

  





</body>
</html>
